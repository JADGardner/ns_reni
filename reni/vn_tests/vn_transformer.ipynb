{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utils import rand_rotation_tensor, test_close\n",
    "\n",
    "# Hyperparameters sweeped from VN-Transformer paper\n",
    "feature_dimension = {32, 64, 128, 256, 512, 1024}\n",
    "number_of_attention_heads = {4, 8, 16, 32, 64, 128}\n",
    "hidden_layer_dimension_in_encoder_VN_MLP = {32, 64, 128, 256, 512}\n",
    "learning_rate = 10^-3\n",
    "learning_rate_schedule = \"linear_decay\"\n",
    "optimizer = \"Adam\"\n",
    "epochs = 4000\n",
    "epsilon_VN_With_Bias = {0, 10^-6}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation-equivariant Attention\n",
    "\n",
    "Consider two tensors $Q \\in \\mathbb{R}^{M \\times C \\times 3}$ and $K \\in \\mathbb{R}^{N \\times C \\times 3}$ which can be thought of as sets of $M$ and $N$ tokens respectively, each a $C \\times 3$ matrix. Using the Frobenius  Inner Product, we can define an attention matrix $A(Q, K) \\in \\mathbb{R}^{M \\times N}$ between the two sets as follows:\n",
    "\n",
    "$$\n",
    "A(Q, K)^{(m)} \\triangleq \\operatorname{softmax}\\left(\\frac{1}{\\sqrt{3 C}}\\left[\\left\\langle Q^{(m)}, K^{(n)}\\right\\rangle_F\\right]_{n=1}^N\\right)\n",
    "$$\n",
    "\n",
    "Following [Vaswani et al](https://arxiv.org/abs/1706.03762), we divide the inner products by $\\sqrt{3C}$ since $Q^{(m)}$, $K^{(n)} \\in \\mathbb{R}^{C \\times 3}$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "A(QR, KR) = A(Q,K) \\ \\ \\forall R \\in SO(3)\n",
    "$$\n",
    "\n",
    "e.g. rotation invariant for rotations of both Q and K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A(Q, K) = A(Q, K) is True with eps 1e-15\n",
      "A(QR, KR) = A(Q, K) is True with eps 1e-06\n"
     ]
    }
   ],
   "source": [
    "m, n, c = 8, 5, 7\n",
    "Q = torch.randn(m, c, 3)\n",
    "K = torch.randn(n, c, 3)\n",
    "R = rand_rotation_tensor() # to test rotation-invariance\n",
    "\n",
    "def A(Q, K):\n",
    "  C = Q.shape[1]\n",
    "  scores = torch.sum(torch.einsum(\"mck,nck->mnck\", Q, K), dim=[2,3]) / torch.sqrt(torch.tensor(3 * C))\n",
    "  scores = F.softmax(scores, dim=-1)\n",
    "  return scores\n",
    "\n",
    "# how close are two equal matrices?\n",
    "res, eps = test_close(A(Q, K), A(Q, K))\n",
    "print(f'A(Q, K) = A(Q, K) is {res} with eps {eps:.0e}')\n",
    "\n",
    "# A(QR, KR) = A(Q,K)\n",
    "res, eps = test_close(A(Q @ R, K @ R), A(Q, K))\n",
    "print(f'A(QR, KR) = A(Q, K) is {res} with eps {eps:.0e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the operation VN_Attention:\n",
    "\n",
    "$$\n",
    "\\mathrm{VN}\\_\\operatorname{Attention}(Q, K, Z)^{(m)} \\triangleq \\sum_{n=1}^N A(Q, K)^{(m, n)} Z^{(n)}\n",
    "$$\n",
    "\n",
    "Where $\\mathrm{VN}\\_\\operatorname{Attention} : \\mathbb{R}^{M \\times C \\times 3} \\times \\mathbb{R}^{N \\times C \\times 3} \\times \\mathbb{R}^{N \\times C' \\times 3} \\rightarrow \\mathbb{R}^{M \\times C' \\times 3} $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VN_Attention(QR, KR, ZR) != VN_Attention(Q, K, Z) is True\n",
      "VN_Attention(QR, KR, ZR) = VN_Attention(Q, K, Z) R is True with eps 1e-06\n"
     ]
    }
   ],
   "source": [
    "def VN_Attention(Q, K, Z):\n",
    "    \"\"\"\n",
    "      Q size M, C,  3 \n",
    "      K size N, C,  3\n",
    "      Z size N, C', 3\n",
    "\n",
    "      rotation-equivariant with respect to rotations of all inputs\n",
    "    \"\"\"\n",
    "    C = Q.shape[1]\n",
    "\n",
    "    # frombenius inner product between Q and K\n",
    "    # to produce rotation invariant attention scores\n",
    "    scores = torch.sum(torch.einsum(\"mck,nck->mnck\", Q, K), dim=[2,3]) / torch.sqrt(torch.tensor(3 * C))\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    # apply attention scores to Z\n",
    "    # this is rotation-equivariant\n",
    "    output = torch.einsum('mn,nck->mck', scores, Z)\n",
    "\n",
    "    return output\n",
    "\n",
    "m, n, c, c_prime = 8, 5, 7, 12\n",
    "Q = torch.rand(m, c, 3)\n",
    "K = torch.rand(n, c, 3)\n",
    "Z = torch.rand(n, c_prime, 3)\n",
    "R = rand_rotation_tensor() # to test rotation-invariance\n",
    "\n",
    "# VN_Attention(QR, KR, ZR) != VN_Attention(Q, K, Z)\n",
    "res, _ = test_close(VN_Attention(Q @ R, K @ R, Z @ R), VN_Attention(Q, K, Z))\n",
    "print(f'VN_Attention(QR, KR, ZR) != VN_Attention(Q, K, Z) is {not res}')\n",
    "\n",
    "# VN_Attention(QR, KR, ZR) = VN_Attention(Q, K, Z) R\n",
    "res, eps = test_close(VN_Attention(Q @ R, K @ R, Z @ R), VN_Attention(Q, K, Z) @ R)\n",
    "print(f'VN_Attention(QR, KR, ZR) = VN_Attention(Q, K, Z) R is {res} with eps {eps:.0e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is extendable to multi-head attention with $H$ heads, $\\mathrm{VN}\\_\\operatorname{MultiHeadAttention} : \\mathbb{R}^{M \\times C \\times 3} \\times \\mathbb{R}^{N \\times C \\times 3} \\times \\mathbb{R}^{N \\times C' \\times 3} \\rightarrow \\mathbb{R}^{M \\times C' \\times 3} $ \n",
    "\n",
    "$$\n",
    "\\mathrm{VN}\\_\\operatorname{MultiHeadAttention}(Q, K, Z) \\triangleq W^{O} \\left [ \\mathrm{VN}\\_\\operatorname{Attention}(W^{Q}_{h}Q, W^{K}_{h}K, W^{Z}_{h}Z) \\right ]^{H}_{h = 1}\n",
    "$$\n",
    "\n",
    "Where $W^{Q}_{h}, W^{K}_{h} \\in \\mathbb{R}^{P \\times C}, \\ W^{Z}_{h} \\in \\mathbb{R}^{C' \\times HP}$ Where $H$ and $P$ are set such that $HP = C'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VN_AttentionHead(nn.Module):\n",
    "  def __init__(self, p, c, c_prime):\n",
    "    super(VN_AttentionHead, self).__init__()\n",
    "    self.W_q = torch.rand(p, c)\n",
    "    self.W_k = torch.rand(p, c)\n",
    "    self.W_z = torch.rand(p, c_prime)\n",
    "\n",
    "  def forward(self, q, k, z):\n",
    "\n",
    "    q = torch.einsum('pc,mck->mck', self.W_q, q)\n",
    "    k = torch.einsum('pc,nck->nck', self.W_k, k)\n",
    "    z = torch.einsum('pc,nck->nck', self.W_z, z)\n",
    "\n",
    "    return VN_Attention(q, k, z)\n",
    "\n",
    "class VN_MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, p, c, c_prime):\n",
    "        super(VN_MultiHeadAttention, self).__init__()\n",
    "        self.W_o = torch.rand(c_prime, num_heads * p)\n",
    "        \n",
    "        self.heads = nn.ModuleList(\n",
    "            [VN_AttentionHead(p, c, c_prime) for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, q, k, z):\n",
    "        return torch.einsum('cp,mhk->mpk', self.W_o, torch.cat([head(q, k, z) for head in self.heads], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VN_Att_H(QR, KR, ZR) != VN_Att_H(Q, K, Z) is True\n",
      "VN_Att_H(QR, KR, ZR) = VN_Att_H(Q, K, Z) R is True with eps 1e-06\n"
     ]
    }
   ],
   "source": [
    "m, n, c, c_prime = 8, 5, 7, 12\n",
    "p = 2\n",
    "\n",
    "Q = torch.rand(m, c, 3)\n",
    "K = torch.rand(n, c, 3)\n",
    "Z = torch.rand(n, c_prime, 3)\n",
    "\n",
    "R = rand_rotation_tensor() # to test rotation-invariance\n",
    "\n",
    "VN_Att_H = VN_AttentionHead(p, c, c_prime)\n",
    "\n",
    "# VN_Att_H(QR, KR, ZR) != VN_Att_H(Q, K, Z)\n",
    "res, _ = test_close(VN_Att_H(Q @ R, K @ R, Z @ R), VN_Att_H(Q, K, Z))\n",
    "print(f'VN_Att_H(QR, KR, ZR) != VN_Att_H(Q, K, Z) is {not res}')\n",
    "\n",
    "# VN_Att_H(QR, KR, ZR) = VN_Att_H(Q, K, Z) R\n",
    "res, eps = test_close(VN_Att_H(Q @ R, K @ R, Z @ R), VN_Att_H(Q, K, Z) @ R)\n",
    "print(f'VN_Att_H(QR, KR, ZR) = VN_Att_H(Q, K, Z) R is {res} with eps {eps:.0e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VN_MHA(QR, KR, ZR) != VN_MHA(Q, K, Z) is True\n",
      "VN_MHA(QR, KR, ZR) = VN_MHA(Q, K, Z) R is True with eps 1e-04\n"
     ]
    }
   ],
   "source": [
    "m, n, c, c_prime = 8, 5, 7, 12\n",
    "p = 2\n",
    "h = c_prime // p\n",
    "\n",
    "Q = torch.rand(m, c, 3)\n",
    "K = torch.rand(n, c, 3)\n",
    "Z = torch.rand(n, c_prime, 3)\n",
    "\n",
    "R = rand_rotation_tensor() # to test rotation-invariance\n",
    "\n",
    "VN_MHA = VN_MultiHeadAttention(h, p, c, c_prime)\n",
    "\n",
    "# # VN_MHA(QR, KR, ZR) != VN_MHA(Q, K, Z)\n",
    "res, _ = test_close(VN_MHA(Q @ R, K @ R, Z @ R), VN_MHA(Q, K, Z))\n",
    "print(f'VN_MHA(QR, KR, ZR) != VN_MHA(Q, K, Z) is {not res}')\n",
    "\n",
    "# # VN_MHA(QR, KR, ZR) = VN_MHA(Q, K, Z) R\n",
    "res, eps = test_close(VN_MHA(Q @ R, K @ R, Z @ R), VN_MHA(Q, K, Z) @ R)\n",
    "print(f'VN_MHA(QR, KR, ZR) = VN_MHA(Q, K, Z) R is {res} with eps {eps:.0e}') # epsilon is decreasing so not sure if this is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation-Equivariant Layer Normalisation\n",
    "\n",
    "\n",
    "$\\mathrm{VN}\\_\\operatorname{LayerNorm}(V^{(n)}) \\triangleq \\left [ \\frac{V^{(n, c)}}{\\left \\| V^{(n, c)} \\right \\|_{2}} \\right ]_{c=1}^{C} \\odot LayerNorm(\\left [ \\left \\| V^{(n, c)} \\right \\|_{2} \\right ]_{c=1}^{C})$ ðŸ™$_{1 \\times 3}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layernorm(VR) != layernorm(V) is True\n",
      "layernorm(VR) = layernorm(V) @ R is True with eps 1e-06\n"
     ]
    }
   ],
   "source": [
    "class VNLayerNorm(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(VNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(in_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: tensor of shape (B, C, 3)\n",
    "        '''\n",
    "        row_wise_norm = torch.norm(x, dim=-1)\n",
    "        # row wise division of x by row_wise_norm\n",
    "        x = torch.einsum('bck,bc->bck', x, 1 / row_wise_norm)\n",
    "        ln = self.layer_norm(row_wise_norm)\n",
    "        # row wise multiplication of x by ln\n",
    "        x = torch.einsum('bck,bc->bck', x, ln)\n",
    "        return x\n",
    "\n",
    "n, c = 8, 12\n",
    "R = rand_rotation_tensor() # to test rotation-invariance\n",
    "V = torch.rand(n, c, 3)\n",
    "layernorm = VNLayerNorm(c)\n",
    "\n",
    "# layernorm(VR) != layernorm(V)\n",
    "res, _ = test_close(layernorm(V @ R), layernorm(V))\n",
    "print(f'layernorm(VR) != layernorm(V) is {not res}')\n",
    "\n",
    "# layernorm(VR) = layernorm(V) R\n",
    "res, eps = test_close(layernorm(V @ R), layernorm(V) @ R)\n",
    "print(f'layernorm(VR) = layernorm(V) @ R is {res} with eps {eps:.0e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation-Invariant Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vnn.vn_models import VN_DGCNN as VN_MLP\n",
    "\n",
    "class VN_Transformer_Classifier(nn.Module):\n",
    "    def __init__(self, vn_mlp_hidden_dim, feature_dimension, attention_heads):\n",
    "        super(VN_Transformer_Classifier, self).__init__()\n",
    "        self.vn_mlp = VN_MLP(c_dim=feature_dimension, dim=3, hidden_dim=vn_mlp_hidden_dim, k=20, meta_output='invariant_latent')\n",
    "        self.attention = VN_MultiHeadAttention(attention_heads, feature_dimension // attention_heads, c, feature_dimension)\n",
    "        self.layer_norm = VNLayerNorm(c_prime)\n",
    "        self.W = torch.rand(num_classes, c_prime)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('reni')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea314ca365037f011d299bb370497356c8ce23b30c323c45d4d9aff78c21879d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
