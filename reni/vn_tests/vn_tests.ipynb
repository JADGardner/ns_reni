{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utils import rand_rotation_tensor, test_close\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm testing the provided layers by VN. They implement a network called DGCNN that (if I remove the last 'pool' layer) takes in as input a batch of points and outputs both invariant and equivariant features for those points:\n",
    "\n",
    "\n",
    "$$\n",
    "VN\\_DGCNN : \\mathbb{R}^{B \\times N \\times 3} \\rightarrow \\mathbb{R}^{B \\times C \\times N \\times 3}\n",
    "$$\n",
    "\n",
    "Where $B$ is Batch Size, $N$ is Number of Points and $C$ is Latent Feature Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of equivariant output: torch.Size([2, 9, 26, 3]), [B, C, N, 3]\n",
      "Size of invariant latent code: torch.Size([2, 9, 26, 3]), [B, C, N, 3]\n",
      "Output: VN_MLP(P @ R) != VN_MLP(P) = False with eps 1e-02\n",
      "Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: True with eps 1e-07\n",
      "Latent: VN_MLP(P @ R) = VN_MLP(P) --> Invariance: True with eps 1e-07\n"
     ]
    }
   ],
   "source": [
    "from vnn.vn_models import VN_MLP, VN_DGCNN\n",
    "\n",
    "# c_dim: latnet code size\n",
    "# dim: input dimension (3 for point clouds (xyz))\n",
    "# hidden_dim: hidden dimension of the MLP\n",
    "# k: number of nearest neighbors in the graph convolution\n",
    "# meta_output: for outputting the invariant latent code\n",
    "model = VN_DGCNN(c_dim=9, dim=3, hidden_dim=128, k=20, meta_output='invariant_latent')\n",
    "\n",
    "# generate batches of random 3D vectors\n",
    "vectors = torch.rand(2, 25, 3)\n",
    "\n",
    "# normalise onto a unit sphere (don't need to do this, just thinking about spherical signals)\n",
    "# output is the still invariant and equivariant either way\n",
    "vectors = vectors / torch.norm(vectors, dim=-1, keepdim=True)\n",
    "\n",
    "conditional = torch.rand(2, 1, 3) # B x Number of Conditonal Variables x 3 \n",
    "# this is encoding the conditional variable in the xyz space, lat on x axis, lon on y axis, z is 0\n",
    "conditional[:, :, 2] = 0\n",
    "\n",
    "# concatenate the conditional variable to the input\n",
    "vectors = torch.cat([vectors, conditional], dim=1)\n",
    "\n",
    "# generate a random rotation matrix\n",
    "R = rand_rotation_tensor()\n",
    "\n",
    "# test equivariance of output and invariance of latent code\n",
    "output, lc = model(vectors)\n",
    "output_R, lc_r = model(vectors @ R)\n",
    "\n",
    "print(f'Size of equivariant output: {output.shape}, [B, C, N, 3]')\n",
    "print(f'Size of invariant latent code: {lc.shape}, [B, C, N, 3]')\n",
    "\n",
    "res, eps = test_close(output, output_R)\n",
    "print(f'Output: VN_MLP(P @ R) != VN_MLP(P) = {not res} {f\"with eps {eps:.0e}\" if res else \"\"}')\n",
    "\n",
    "res, eps = test_close(output_R, output @ R)\n",
    "print(f'Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: {res} with eps {eps:.0e}')\n",
    "\n",
    "res, eps = test_close(lc_r, lc)\n",
    "print(f'Latent: VN_MLP(P @ R) = VN_MLP(P) --> Invariance: {res} with eps {eps:.0e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this works and provides both invariant and equivarient features.\n",
    "\n",
    "But according to the VN-Transformer paper they use a simple VN-MLP with only VN-Linear, VN-BatchNorm and VN-ReLU. No pooling layers as used in VN\\_DGCNN and they also do not use the graph convolution layer which is the first two layers of VN\\_DGCNN. \n",
    "\n",
    "VN paper discribes the reason for this graph convolution layer as:\n",
    "\n",
    "<em>\"\"In the first input layer where the input pointcloud coordinates are $\\mathbb{R}^{1 \\times 3}$ vectors and thus applying $f$ to them would degenerate to a set of $\\mathbb{R}^{C \\times 3}$ vector-lists whose vector components are all linearly dependent (pointing to one direction). This is analogous to applying a per-pixel $1 \\times 1$ convolution to a gray-scale image (single input channel). Therefore, in we add an edge convolution at the input layer, mapping $\\mathbb{R}^{1 \\times 3}$ features into $\\mathbb{R}^{C \\times 3}$ with $C > 1$ and then continue with per-point VN-MLP operations.\"\"</em>\n",
    "\n",
    "And VN-Transformer paper says:\n",
    "\n",
    "<em>\"\"The original VN paper relied on edge convolution as a pre-processing step to capture local point-cloud structure. Such feature engineering is not data-driven and requires human involvement in designing and tuning. Moreover, the sparsity of these computations makes them slow to run on accelerated hardware. Our proposed rotation-equivariant attention mechanism learns higher-level features directly from single points for arbitrary point-clouds\"\"</em>\n",
    "\n",
    "So I would like to not use them. But as shown below the networks I build do not have rotation equivariance/invariance :/\n",
    "\n",
    "It seems removing that edge convolution is an issue and I can't find a good explination of what they did in the VN-Transformer paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing building a simple VN-MLP and not using the graph convolution\n",
    "from vnn.vn_layers import VNLinear, VNLeakyReLU, VNBatchNorm\n",
    "\n",
    "# So I do not know if this is correct, but as we are not going to use the \n",
    "# edge convolution and the first few layers of VN_DGCNN are doing this:\n",
    "#\n",
    "#  p = p.unsqueeze(1).transpose(2, 3) # [B, N, 3] -> [B, 1, 3, N]\n",
    "#  feat = get_graph_feature_cross(p, k=self.k, dims=3) # [B, 1, 3, N] -> [B, 3, 3, N, K]\n",
    "#  net = self.conv_pos(feat) # [B, 3, 3, N, K] -> [B, Z, 3, N, K]\n",
    "#  net = self.pool(net, dim=-1) # [B, Z, 3, N, K] -> [B, Z, 3, N]\n",
    "\n",
    "# Where the output is [B, Z, 3, N]. So I tried skipping this and going straight to [B, 1, 3, N]\n",
    "# so input to VNLInear is dim 1. \n",
    "linear_0 = VNLinear(in_channels=1, out_channels=5)\n",
    "\n",
    "batch_norm_0 = VNBatchNorm(num_features=5, dim=5) # dim=5 results in nn.BatchNorm2d where as dim=3 | 4 results in nn.BatchNorm1d\n",
    "\n",
    "leaky_relu_0 = VNLeakyReLU(5, share_nonlinearity=False, negative_slope=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of equivariant output: torch.Size([2, 5, 4, 3]), [B, C, N, 3]\n",
      "Output: VN_MLP(P @ R) != VN_MLP(P) = True \n",
      "Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: True with eps 1e-07\n"
     ]
    }
   ],
   "source": [
    "# generate batches of random 3D vectors where the feature dimension is 1\n",
    "B, C, N = 2, 1, 4\n",
    "vectors = torch.rand(B, C, N, 3)\n",
    "vectors = vectors / torch.norm(vectors, dim=-1, keepdim=True)\n",
    "\n",
    "R = rand_rotation_tensor()\n",
    "vectors_R = vectors @ R\n",
    "p = vectors.transpose(2, 3) # they do this inside the VN_DGCNN forward pass\n",
    "p_R = vectors_R.transpose(2, 3) # they do this inside the VN_DGCNN forward pass\n",
    "x1 = linear_0(p)\n",
    "x1_R = linear_0(p_R)\n",
    "x1 = x1.transpose(2, 3) # I undo it here to be able to apply rotation matrices to test equivariance\n",
    "x1_R = x1_R.transpose(2, 3) # I undo it here to be able to apply rotation matrices to test equivariance\n",
    "\n",
    "print(f'Size of equivariant output: {x1.shape}, [B, C, N, 3]')\n",
    "\n",
    "res, eps = test_close(x1, x1_R)\n",
    "print(f'Output: VN_MLP(P @ R) != VN_MLP(P) = {not res} {f\"with eps {eps:.0e}\" if res else \"\"}')\n",
    "\n",
    "res, eps = test_close(x1_R, x1 @ R)\n",
    "print(f'Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: {res} with eps {eps:.0e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑↑↑↑ This appears to be working ↑↑↑↑ \n",
    "\n",
    "So now test VN-BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of equivariant output: torch.Size([2, 5, 4, 3]), [B, C, N, 3]\n",
      "Output: VN_MLP(P @ R) != VN_MLP(P) = False with eps 1e-04\n",
      "Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: True with eps 1e-04\n"
     ]
    }
   ],
   "source": [
    "x2 = x1.transpose(2, 3)\n",
    "x2_R = x1_R.transpose(2, 3)\n",
    "x2 = batch_norm_0(x2.unsqueeze(4)).squeeze()\n",
    "x2_R = batch_norm_0(x2_R.unsqueeze(4)).squeeze()\n",
    "x2 = x2.transpose(2, 3)\n",
    "x2_R = x2_R.transpose(2, 3)\n",
    "\n",
    "print(f'Size of equivariant output: {x2.shape}, [B, C, N, 3]')\n",
    "\n",
    "res, eps = test_close(x2, x2_R)\n",
    "print(f'Output: VN_MLP(P @ R) != VN_MLP(P) = {not res} {f\"with eps {eps:.0e}\" if res else \"\"}')\n",
    "\n",
    "res, eps = test_close(x2_R, x2 @ R)\n",
    "print(f'Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: {res} {f\"with eps {eps:.0e}\" if res else \"\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as shown above the BatchNorm layer has seriously affected the equivariance property such that you need a significantly larger epsilon in the test_close function for it to pass. Something is wrong here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of equivariant output: torch.Size([2, 5, 4, 3]), [B, C, N, 3]\n",
      "Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: True with eps 1e-04\n"
     ]
    }
   ],
   "source": [
    "x3 = x2.transpose(2, 3)\n",
    "x3_R = x2_R.transpose(2, 3)\n",
    "x3 = leaky_relu_0(x3)\n",
    "x3_R = leaky_relu_0(x3_R)\n",
    "x3 = x3.transpose(2, 3)\n",
    "x3_R = x3_R.transpose(2, 3)\n",
    "\n",
    "print(f'Size of equivariant output: {x3.shape}, [B, C, N, 3]')\n",
    "\n",
    "res, eps = test_close(x3_R, x3 @ R)\n",
    "print(f'Output: VN_MLP(P @ R) = VN_MLP(P) @ R --> Equivariance: {res} with eps {eps:.0e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('reni')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea314ca365037f011d299bb370497356c8ce23b30c323c45d4d9aff78c21879d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
